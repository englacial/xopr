{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Bedmap Data Query Demo\n",
    "\n",
    "This notebook demonstrates querying bedmap data from cloud-hosted GeoParquet files:\n",
    "1. Querying the STAC catalog to find matching data files\n",
    "2. Using DuckDB for efficient partial reads with spatial/temporal filters\n",
    "3. Visualizing query results\n",
    "4. Comparing bedmap with OPR layer data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from datetime import datetime, timezone\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import box, Point\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Import xopr bedmap modules\n",
    "from xopr.bedmap import (\n",
    "    query_bedmap,\n",
    "    query_bedmap_catalog,\n",
    "    compare_with_opr,\n",
    "    match_bedmap_to_opr\n",
    ")\n",
    "\n",
    "print(\"xopr bedmap module loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## 1. Query Bedmap Data from Cloud\n",
    "\n",
    "The bedmap data is hosted on Google Cloud Storage at `gs://opr_stac/bedmap/`.\n",
    "The query process works in two stages:\n",
    "1. **STAC Catalog Query**: Find GeoParquet files that intersect with the query geometry/time\n",
    "2. **DuckDB Partial Reads**: Fetch only relevant rows from those files using SQL pushdown\n",
    "\n",
    "This approach minimizes data transfer - only the data you need is downloaded!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a query region (Dronning Maud Land example)\n",
    "query_bbox = box(-20, -76, -5, -72)  # lon_min, lat_min, lon_max, lat_max\n",
    "\n",
    "# Visualize the query region\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "world = gpd.GeoDataFrame([1], geometry=[box(-180, -90, 180, 90)], crs='EPSG:4326')\n",
    "antarctica = gpd.GeoDataFrame([1], geometry=[box(-180, -90, 180, -60)], crs='EPSG:4326')\n",
    "query_region = gpd.GeoDataFrame([1], geometry=[query_bbox], crs='EPSG:4326')\n",
    "\n",
    "world.plot(ax=ax, color='lightgray', edgecolor='black')\n",
    "antarctica.plot(ax=ax, color='white', edgecolor='black')\n",
    "query_region.plot(ax=ax, color='red', alpha=0.3, edgecolor='red', linewidth=2)\n",
    "\n",
    "ax.set_xlim(-40, 10)\n",
    "ax.set_ylim(-80, -65)\n",
    "ax.set_xlabel('Longitude')\n",
    "ax.set_ylabel('Latitude')\n",
    "ax.set_title('Query Region (Red Box) - Dronning Maud Land')\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(f\"Query bbox: {query_bbox.bounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, query the catalog to see what files match our region\n",
    "print(\"Querying STAC catalog for matching files...\")\n",
    "\n",
    "catalog_items = query_bedmap_catalog(\n",
    "    catalog_path='gs://opr_stac/bedmap/',\n",
    "    geometry=query_bbox,\n",
    "    collections=['bedmap2']  # Filter by bedmap version\n",
    ")\n",
    "\n",
    "if not catalog_items.empty:\n",
    "    print(f\"\\nFound {len(catalog_items)} matching files:\")\n",
    "    for _, row in catalog_items.iterrows():\n",
    "        print(f\"  - {row['name']}: {row['row_count']:,} rows\")\n",
    "else:\n",
    "    print(\"No matching files found. Try a different region or bedmap version.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now query the actual data from cloud storage\n",
    "print(\"Querying bedmap data from cloud GeoParquet files...\")\n",
    "print(f\"Query region: {query_bbox.bounds}\")\n",
    "print()\n",
    "\n",
    "# Query with spatial filter - data is fetched directly from GCS\n",
    "result_df = query_bedmap(\n",
    "    geometry=query_bbox,\n",
    "    collections=['bedmap2'],\n",
    "    max_rows=5000,  # Limit for demo\n",
    "    exclude_geometry=True\n",
    ")\n",
    "\n",
    "if not result_df.empty:\n",
    "    print(f\"\\nRetrieved {len(result_df):,} points\")\n",
    "    print(\"\\nFirst 5 rows:\")\n",
    "    display(result_df.head())\n",
    "    \n",
    "    print(\"\\nData summary:\")\n",
    "    numeric_cols = result_df.select_dtypes(include=[np.number]).columns\n",
    "    display(result_df[numeric_cols].describe())\n",
    "else:\n",
    "    print(\"No data found in query region.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 2. Visualize Query Results\n",
    "\n",
    "Let's visualize the retrieved data points and their properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not result_df.empty and 'lon' in result_df.columns and 'lat' in result_df.columns:\n",
    "    # Create GeoDataFrame for visualization\n",
    "    gdf = gpd.GeoDataFrame(\n",
    "        result_df,\n",
    "        geometry=gpd.points_from_xy(result_df['lon'], result_df['lat']),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    \n",
    "    # Find available columns for plotting\n",
    "    surface_col = None\n",
    "    thickness_col = None\n",
    "    for col in result_df.columns:\n",
    "        if 'surface' in col.lower() and 'altitude' in col.lower():\n",
    "            surface_col = col\n",
    "        if 'thickness' in col.lower():\n",
    "            thickness_col = col\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "    \n",
    "    # Plot 1: Surface altitude (if available)\n",
    "    ax1 = axes[0]\n",
    "    if surface_col and surface_col in gdf.columns:\n",
    "        gdf.plot(column=surface_col, \n",
    "                 ax=ax1, \n",
    "                 legend=True,\n",
    "                 cmap='terrain',\n",
    "                 markersize=10,\n",
    "                 legend_kwds={'label': 'Surface Altitude (m)'})\n",
    "        ax1.set_title('Surface Altitude')\n",
    "    else:\n",
    "        gdf.plot(ax=ax1, markersize=10, color='blue')\n",
    "        ax1.set_title('Data Points')\n",
    "    query_region.boundary.plot(ax=ax1, color='red', linewidth=2)\n",
    "    ax1.set_xlabel('Longitude')\n",
    "    ax1.set_ylabel('Latitude')\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Ice thickness (if available)\n",
    "    ax2 = axes[1]\n",
    "    if thickness_col and thickness_col in gdf.columns:\n",
    "        gdf.plot(column=thickness_col, \n",
    "                 ax=ax2, \n",
    "                 legend=True,\n",
    "                 cmap='Blues',\n",
    "                 markersize=10,\n",
    "                 legend_kwds={'label': 'Ice Thickness (m)'})\n",
    "        ax2.set_title('Ice Thickness')\n",
    "    else:\n",
    "        gdf.plot(ax=ax2, markersize=10, color='blue')\n",
    "        ax2.set_title('Data Points')\n",
    "    query_region.boundary.plot(ax=ax2, color='red', linewidth=2)\n",
    "    ax2.set_xlabel('Longitude')\n",
    "    ax2.set_ylabel('Latitude')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No data to visualize.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## 3. Query with Temporal Filter\n",
    "\n",
    "You can also filter by date range to find data from specific time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query with both spatial and temporal filters\n",
    "from datetime import datetime\n",
    "\n",
    "# Define query parameters\n",
    "query_params = {\n",
    "    'geometry': box(-15, -75, -5, -73),  # Smaller region\n",
    "    'date_range': (datetime(1994, 1, 1), datetime(2000, 12, 31)),  # 1994-2000\n",
    "    'collections': ['bedmap2'],\n",
    "    'max_rows': 2000,\n",
    "}\n",
    "\n",
    "print(\"Query parameters:\")\n",
    "print(f\"  Spatial: {query_params['geometry'].bounds}\")\n",
    "print(f\"  Temporal: {query_params['date_range'][0]} to {query_params['date_range'][1]}\")\n",
    "print(f\"  Collections: {query_params['collections']}\")\n",
    "print(f\"  Max rows: {query_params['max_rows']}\")\n",
    "\n",
    "# Execute query\n",
    "temporal_result = query_bedmap(**query_params)\n",
    "\n",
    "if not temporal_result.empty:\n",
    "    print(f\"\\nRetrieved {len(temporal_result):,} points\")\n",
    "    \n",
    "    # Show unique source files\n",
    "    if 'source_file' in temporal_result.columns:\n",
    "        print(f\"\\nSource files:\")\n",
    "        for src in temporal_result['source_file'].unique():\n",
    "            count = (temporal_result['source_file'] == src).sum()\n",
    "            print(f\"  - {src}: {count:,} points\")\n",
    "else:\n",
    "    print(\"No data found for the specified query.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## 4. Compare with OPR Data (Example)\n",
    "\n",
    "The comparison functions allow matching bedmap measurements with OPR layer picks.\n",
    "This example shows how the matching works with mock OPR data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "\n",
    "if not result_df.empty and 'lon' in result_df.columns:\n",
    "    # Create a mock OPR dataset for demonstration\n",
    "    # In practice, this would be loaded from actual OPR files\n",
    "    n_opr_points = 100\n",
    "    opr_lons = np.random.uniform(\n",
    "        result_df['lon'].min(),\n",
    "        result_df['lon'].max(),\n",
    "        n_opr_points\n",
    "    )\n",
    "    opr_lats = np.random.uniform(\n",
    "        result_df['lat'].min(),\n",
    "        result_df['lat'].max(),\n",
    "        n_opr_points\n",
    "    )\n",
    "    \n",
    "    # Create mock surface and bed elevations\n",
    "    opr_surface = np.random.normal(2000, 200, n_opr_points)\n",
    "    opr_bed = np.random.normal(500, 100, n_opr_points)\n",
    "    \n",
    "    # Create xarray dataset\n",
    "    opr_dataset = xr.Dataset({\n",
    "        'Longitude': (('slow_time',), opr_lons),\n",
    "        'Latitude': (('slow_time',), opr_lats),\n",
    "        'Surface': (('slow_time',), opr_surface),\n",
    "        'Bottom': (('slow_time',), opr_bed),\n",
    "    })\n",
    "    \n",
    "    print(\"Mock OPR dataset created:\")\n",
    "    print(opr_dataset)\n",
    "    \n",
    "    # Match bedmap points to nearest OPR measurements\n",
    "    bedmap_subset = gpd.GeoDataFrame(\n",
    "        result_df.head(50),\n",
    "        geometry=gpd.points_from_xy(result_df.head(50)['lon'], result_df.head(50)['lat']),\n",
    "        crs='EPSG:4326'\n",
    "    )\n",
    "    \n",
    "    matched_data = match_bedmap_to_opr(\n",
    "        bedmap_subset,\n",
    "        opr_dataset,\n",
    "        max_distance_m=10000  # 10 km matching tolerance for demo\n",
    "    )\n",
    "    \n",
    "    # Show matching results\n",
    "    print(f\"\\nMatching results:\")\n",
    "    print(f\"  Total bedmap points: {len(matched_data)}\")\n",
    "    print(f\"  Matched points: {matched_data['is_matched'].sum()}\")\n",
    "    print(f\"  Average match distance: {matched_data['opr_match_distance_m'].mean():.1f} m\")\n",
    "else:\n",
    "    print(\"No data available for comparison demo.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 5. Summary\n",
    "\n",
    "This demo showed the bedmap query workflow:\n",
    "\n",
    "### Key Features:\n",
    "- **Cloud-native queries**: Data is hosted on GCS and queried directly without downloading full files\n",
    "- **STAC catalog**: Find relevant files using spatial/temporal filters\n",
    "- **DuckDB partial reads**: Efficient SQL pushdown to read only needed rows\n",
    "- **OPR comparison**: Match bedmap measurements with radar layer picks\n",
    "\n",
    "### Query Process:\n",
    "1. **STAC Query** - Find files intersecting with query geometry/time\n",
    "2. **DuckDB Partial Reads** - Fetch only rows within bounding box\n",
    "3. **Optional Refinement** - Apply precise geometry filter if needed\n",
    "\n",
    "### Data Location:\n",
    "- Catalog: `gs://opr_stac/bedmap/bedmap{1,2,3}.parquet`\n",
    "- Data: `gs://opr_stac/bedmap/data/*.parquet`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
