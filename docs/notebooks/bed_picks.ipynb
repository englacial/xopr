{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb5ffcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befe8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xopr\n",
    "\n",
    "import holoviews as hv\n",
    "import xarray as xr\n",
    "import hvplot\n",
    "import hvplot.xarray\n",
    "import hvplot.pandas\n",
    "import geoviews.feature as gf\n",
    "import cartopy.crs as ccrs\n",
    "import rioxarray\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import verde as vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b0a671",
   "metadata": {},
   "outputs": [],
   "source": [
    "opr = xopr.OPRConnection(cache_dir='radar_cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65507af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsg_3031 = ccrs.Stereographic(central_latitude=-90, true_scale_latitude=-71)\n",
    "coastline = gf.coastline.options(scale='50m').opts(projection=epsg_3031)\n",
    "velocity = rioxarray.open_rasterio(\n",
    "    \"https://its-live-data.s3.amazonaws.com/velocity_mosaic/v2/static/cog/ITS_LIVE_velocity_120m_RGI19A_0000_v02_v.tif\",\n",
    "    chunks='auto', overview_level=4, cache=False\n",
    ").squeeze().drop_vars(['spatial_ref', 'band']).rename('velocity (m/year)')\n",
    "velocity_map = velocity.hvplot.image(x='x', y='y', cmap='gray_r').opts(clim=(0,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb42795",
   "metadata": {},
   "outputs": [],
   "source": [
    "region = xopr.geometry.get_antarctic_regions(name=[\"Vincennes_Bay\", \"Underwood\"], merge_regions=True, simplify_tolerance=100)\n",
    "region_projected = xopr.geometry.project_geojson(region, source_crs='EPSG:4326', target_crs=\"EPSG:3031\")\n",
    "\n",
    "region_hv = hv.Polygons([region_projected]).opts(\n",
    "    color='green',\n",
    "    line_color='black',\n",
    "    fill_alpha=0.3)\n",
    "\n",
    "(velocity_map * coastline * region_hv).opts(aspect='equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675238b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = opr.query_frames(geometry=region).to_crs('EPSG:3031')\n",
    "print(f\"Found {len(gdf)} radar frames in the selected region.\")\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde48ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_frames_hv = gdf.hvplot(by='collection', hover_cols=['id'])\n",
    "(velocity_map * coastline * region_hv * radar_frames_hv).opts(aspect='equal', legend_position='top_left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204073ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_ds_list = []\n",
    "\n",
    "with tqdm(gdf.iterrows(), total=len(gdf)) as t:\n",
    "    for id, frame in t:\n",
    "        t.set_description(f\"{id}\")\n",
    "        layers = opr.get_layers(frame)\n",
    "        bed_layer_name = None\n",
    "        if 'standard:bottom' in layers:\n",
    "            bed_layer_name = 'standard:bottom'\n",
    "        elif ':bottom' in layers:\n",
    "            bed_layer_name = ':bottom'\n",
    "        else:\n",
    "            continue  # No bed layer found\n",
    "        layer_wgs84 = xopr.radar_util.layer_twtt_to_range(layers[bed_layer_name], layers[\"standard:surface\"], vertical_coordinate='wgs84').rename({'lat': 'Latitude', 'lon': 'Longitude'})\n",
    "        layer_wgs84 = xopr.geometry.project_dataset(layer_wgs84, target_crs='EPSG:3031')\n",
    "        layer_wgs84 = layer_wgs84.dropna('slow_time', subset=['wgs84'])\n",
    "        layer_wgs84['source'] = id\n",
    "        layer_ds_list.append(layer_wgs84)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce35862",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_merged = xr.concat(layer_ds_list, dim='slow_time')\n",
    "xlim = (bed_merged.x.min().item(), bed_merged.x.max().item())\n",
    "ylim = (bed_merged.y.min().item(), bed_merged.y.max().item())\n",
    "bed_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1823f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_hv = bed_merged.hvplot.scatter(x='x', y='y', c='wgs84', cmap='turbo', s=2).opts(clabel='Bed Elevation WGS84 (m)')\n",
    "(velocity_map.opts(colorbar=False) * coastline * region_hv * radar_frames_hv * bed_hv).opts(aspect='equal', legend_position='top_left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5f0701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_dataarray(d: xr.DataArray, spacing=1000, aggregation_fns={'median': \"median\", 'std': 'std', 'count': \"count\"}):\n",
    "    \"\"\"\n",
    "    Grid a DataArray with x,y coordinates into a regular grid using block aggregation.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    d : xr.DataArray\n",
    "        Input DataArray with 'x' and 'y' coordinates\n",
    "    spacing : float\n",
    "        Grid spacing in the same units as x,y coordinates\n",
    "    aggregation_fns : dict\n",
    "        Dictionary mapping aggregation function names to functions (e.g., {'median': np.median, 'std': np.std})\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    xr.Dataset\n",
    "        Dataset with variables named {d.name}_{fn_name} for each aggregation function\n",
    "    \"\"\"\n",
    "    # Get data extent\n",
    "    x_min = d['x'].min().values\n",
    "    x_max = d['x'].max().values\n",
    "    y_min = d['y'].min().values\n",
    "    y_max = d['y'].max().values\n",
    "    \n",
    "    # Extract coordinate and data values\n",
    "    x_data = d['x'].values\n",
    "    y_data = d['y'].values\n",
    "    data_values = d.values\n",
    "    \n",
    "    # Create grid coordinates\n",
    "    grid_x, grid_y = vd.grid_coordinates(\n",
    "        region=(x_min, x_max, y_min, y_max),\n",
    "        spacing=spacing\n",
    "    )\n",
    "    \n",
    "    # Dictionary to store gridded results for each aggregation function\n",
    "    data_vars = {}\n",
    "    \n",
    "    for fn_name, fn in aggregation_fns.items():\n",
    "        # Use Verde's BlockReduce with the specified aggregation function\n",
    "        gridder = vd.BlockReduce(\n",
    "            reduction=fn, \n",
    "            spacing=spacing, \n",
    "            region=(x_min, x_max, y_min, y_max),\n",
    "            center_coordinates=True\n",
    "        )\n",
    "        block_coords, block_values = gridder.filter(\n",
    "            coordinates=(x_data, y_data), \n",
    "            data=data_values\n",
    "        )\n",
    "        \n",
    "        # Initialize grid with NaN\n",
    "        grid_data = np.full(grid_x.shape, np.nan)\n",
    "        \n",
    "        # Vectorized approach: compute indices directly from coordinates\n",
    "        x_indices = np.floor((block_coords[0] - x_min) / spacing).astype(int)\n",
    "        y_indices = np.floor((block_coords[1] - y_min) / spacing).astype(int)\n",
    "        \n",
    "        for x_idx, y_idx, value in zip(x_indices.flatten(), y_indices.flatten(), block_values.flatten()):\n",
    "            grid_data[y_idx, x_idx] = value\n",
    "        \n",
    "        # Store in dictionary with name pattern\n",
    "        var_name = f\"{d.name}_{fn_name}\" if d.name else f\"data_{fn_name}\"\n",
    "        data_vars[var_name] = (['y', 'x'], grid_data)\n",
    "    \n",
    "    # Create Dataset with all aggregated variables\n",
    "    return xr.Dataset(\n",
    "        data_vars=data_vars,\n",
    "        coords={\n",
    "            'y': grid_y[:, 0],\n",
    "            'x': grid_x[0, :]\n",
    "        }\n",
    "    )\n",
    "\n",
    "gridded = grid_dataarray(bed_merged['wgs84'], spacing=10000)\n",
    "\n",
    "gridded_median_hv = hv.Image(gridded, kdims=['x', 'y'], vdims=['wgs84_median', 'wgs84_std', 'wgs84_count']).opts(\n",
    "    cmap='turbo',\n",
    "    aspect='equal',\n",
    "    tools=['hover'],\n",
    "    colorbar=True,\n",
    "    clabel='WGS84 Elevation (m)'\n",
    ")\n",
    "\n",
    "gridded_std_hv = hv.Image(gridded, kdims=['x', 'y'], vdims=['wgs84_std', 'wgs84_median', 'wgs84_count']).opts(\n",
    "    cmap='inferno',\n",
    "    aspect='equal',\n",
    "    tools=['hover'],\n",
    "    colorbar=True,\n",
    "    clabel='Std of WGS84 Elevation (m)'\n",
    ")\n",
    "\n",
    "(velocity_map * region_hv * coastline * gridded_median_hv).opts(width=500, aspect='equal', xlim=xlim, ylim=ylim) + \\\n",
    "    (velocity_map * region_hv * coastline * gridded_std_hv).opts(width=500, aspect='equal', xlim=xlim, ylim=ylim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46a90eb8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aba81a31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xopr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
